{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eb2a843-25cf-4bfa-b9b8-0bc00f0a332f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from nltk) (4.67.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba6d747-d05c-41c8-8f29-495dd15f2140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (1.7.4.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (6.30.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (2.9.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (74.1.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (4.67.0)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: webencodings in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f10ab0-4668-47ec-9810-e38ac3aa3d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59aebabe-09c7-4950-ad70-20bd4b28bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"archive.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc1e427d-24cf-482d-86ae-d9f90232980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2cd661e-9fa3-48be-8b12-25a8b70314ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a16667a7-471a-4b87-9d06-d9fea67844a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.NLP Component (Text Analysis) start here with loading and preprocessing the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c621dd7-1571-4bb5-81fa-58fb8f38b33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Image  \\\n",
      "0  [[[-0.5507521  -0.6045698  -0.6229138 ]\\n  [-0...   \n",
      "1  [[[-0.5480964  -0.5235891  -0.76556504]\\n  [-0...   \n",
      "2  [[[0.16979091 0.29803866 0.3613662 ]\\n  [0.199...   \n",
      "3  [[[-0.24860182 -0.35181937 -0.4667918 ]\\n  [-0...   \n",
      "4  [[[ 0.20944206  0.12295917  0.06715906]\\n  [ 0...   \n",
      "\n",
      "                                                Text Sentiment  \n",
      "0  I am feeling positive today because I see Tibe...  POSITIVE  \n",
      "1  I am feeling negative today because I see cric...  NEGATIVE  \n",
      "2  I am feeling positive today because I see Cock...  POSITIVE  \n",
      "3  I am feeling negative today because I see Grif...  POSITIVE  \n",
      "4  I am feeling positive today because I see logg...  POSITIVE  \n"
     ]
    }
   ],
   "source": [
    "#Loading the Dataset\n",
    "file_path = \"dataset.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebca001e-8b5c-41d8-a746-086760bc0227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Joshua.Turnbull\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Joshua.Turnbull\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Downloading NLTK resources that I need\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae82ca0a-b9e9-4f34-9eb6-bbf7b7e91568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading text data dataset\n",
    "text_data = data['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b612e67-579e-4f19-acb5-5f4bd7a622ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = data[\"Image\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "460d773b-b6e1-44c0-9a0d-8c173433b4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Joshua.Turnbull\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ccfbec8-9187-4787-87af-4ba3db6aba5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [feeling, positive, today, see, tibetan, terri...\n",
      "1    [feeling, negative, today, see, cricket, feeli...\n",
      "2    [feeling, positive, today, see, cocker, spanie...\n",
      "3    [feeling, negative, today, see, griffon, bruxe...\n",
      "4    [feeling, positive, today, see, loggerhead, se...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    #Applying lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Applying Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    #Applying stopword removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "# Applying preprocessing to the text data\n",
    "processed_text = text_data.apply(preprocess_text)\n",
    "print(processed_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed44d61c-9d1a-4167-a837-43ce40010715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting to extract features using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67f8ae53-50eb-492a-9070-a99c19bb68a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from transformers) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88a97304-447f-4005-8457-e0b564c1cf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (2.6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67d0ab62-3a44-400a-a545-3611da4096a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "#Loading BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a17ff29-cd6e-41a4-ab13-b2e1dc2766b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting BERT Features\n",
    "def get_bert_embeddings(text):\n",
    "    #Tokenizing the text\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Getting BERT embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    #Using the embeddings from the last hidden state\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embeddings\n",
    "\n",
    "#Applying BERT feature extraction\n",
    "bert_features = text_data.apply(get_bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdecd55e-5325-4fa5-a4dd-c029d9e87f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a Sentiment Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5491c050-16df-4a8e-b259-90df3c737466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from scikit-learn) (2.1.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.1 MB 8.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/11.1 MB 6.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.7/11.1 MB 7.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.5/11.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.1 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.2-cp310-cp310-win_amd64.whl (41.2 MB)\n",
      "   ---------------------------------------- 0.0/41.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.1/41.2 MB 13.1 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 4.5/41.2 MB 12.2 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.5/41.2 MB 9.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.3/41.2 MB 9.3 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 9.4/41.2 MB 9.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 12.1/41.2 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 14.4/41.2 MB 10.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.8/41.2 MB 10.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 19.9/41.2 MB 10.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.8/41.2 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 24.9/41.2 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 27.5/41.2 MB 11.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 29.4/41.2 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 32.0/41.2 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 35.7/41.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.7/41.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.6/41.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.2/41.2 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95d2f561-3f3e-4b66-bee8-ca5b9292a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing data for modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labels = data['Sentiment']\n",
    "\n",
    "#Encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "#Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(bert_features.tolist(), encoded_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c93c8159-3766-463b-b9a7-7bb77b3d3b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.9055944055944056\n"
     ]
    }
   ],
   "source": [
    "#Training Sentiment Classification Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Training a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predicting and evaluating the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b226af37-3049-4348-9fd8-42d039113498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Computer Vision Component (Image Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f8943ac-2ed2-49c1-a104-ad2053ba60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af36d4b4-b989-4b84-aaf1-8f0c51222f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (2.6.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torchvision) (2.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joshua.turnbull\\appdata\\local\\miniconda3\\envs\\pydata-book\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading torchvision-0.21.0-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 16.6 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d64ffe2d-c818-47c2-b096-5414a1be911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73256524-1479-4862-8110-d0c1bd8286ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining preprossesing steps\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),          \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "#Resizing images to 224x224 pixels\n",
    "#Converting image to PyTorch tensor\n",
    "#Normalizing using ImageNet standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48600b17-b48e-4acf-bcc1-4146c9a6b5d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Joshua.Turnbull\\\\[[[-0.5507521  -0.6045698  -0.6229138 ]\\n  [-0.63850087 -0.66662765 -0.6978787 ]\\n  [-0.6789291  -0.66646045 -0.6680623 ]\\n  ...\\n  [-0.6993981  -0.7002809  -0.69596666]\\n  [-0.61803526 -0.6082668  -0.60642767]\\n  [-0.5558948  -0.57046324 -0.59524053]]\\n\\n [[-0.5584087  -0.5619373  -0.5744659 ]\\n  [-0.60510385 -0.5802763  -0.5907305 ]\\n  [-0.61694497 -0.55589324 -0.59315443]\\n  ...\\n  [-0.71316266 -0.7144597  -0.65562713]\\n  [-0.62904453 -0.59384894 -0.5559391 ]\\n  [-0.6673803  -0.667725   -0.6671463 ]]\\n\\n [[-0.55703044 -0.5463458  -0.5191123 ]\\n  [-0.53970224 -0.49998084 -0.5225193 ]\\n  [-0.55531585 -0.5167261  -0.5316111 ]\\n  ...\\n  [-0.6966244  -0.7041687  -0.6425341 ]\\n  [-0.53042525 -0.5079934  -0.46229053]\\n  [-0.46439797 -0.5104388  -0.50135607]]\\n\\n ...\\n\\n [[ 0.7684314   0.8806956   0.9020777 ]\\n  [ 0.55004394  0.8354144   0.92739576]\\n  [ 0.2053559   0.6938815   0.89285916]\\n  ...\\n  [ 0.5146159   0.45076168  0.38074565]\\n  [ 0.5077751   0.48318878  0.38308337]\\n  [ 0.38103613  0.35716513  0.2612215 ]]\\n\\n [[ 0.5970726   0.77560246  0.886816  ]\\n  [ 0.3078161   0.78520185  0.9002715 ]\\n  [ 0.19283424  0.7226255   0.8503383 ]\\n  ...\\n  [ 0.49694324  0.4725132   0.36233312]\\n  [ 0.4913761   0.4234206   0.36018938]\\n  [ 0.35868862  0.35483062  0.3554817 ]]\\n\\n [[ 0.22378577  0.5230688   0.71325547]\\n  [ 0.12510037  0.58206564  0.86857504]\\n  [ 0.00471767  0.5722435   0.8313632 ]\\n  ...\\n  [ 0.41076395  0.35539225  0.24901837]\\n  [ 0.4907982   0.42025086  0.33980078]\\n  [ 0.40406707  0.36447364  0.41718984]]]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Preprocessing images\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m images \u001b[38;5;241m=\u001b[39m [load_and_preprocess_image(image_path) \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m image_paths]\n\u001b[0;32m      9\u001b[0m images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(images)  \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#Stacking images into a single tensor\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[41], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Preprocessing images\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m images \u001b[38;5;241m=\u001b[39m [\u001b[43mload_and_preprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m image_paths]\n\u001b[0;32m      9\u001b[0m images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(images)  \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#Stacking images into a single tensor\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m, in \u001b[0;36mload_and_preprocess_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_preprocess_image\u001b[39m(image_path):\n\u001b[1;32m----> 3\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     image \u001b[38;5;241m=\u001b[39m preprocess(image)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\pydata-book\\lib\\site-packages\\PIL\\Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Joshua.Turnbull\\\\[[[-0.5507521  -0.6045698  -0.6229138 ]\\n  [-0.63850087 -0.66662765 -0.6978787 ]\\n  [-0.6789291  -0.66646045 -0.6680623 ]\\n  ...\\n  [-0.6993981  -0.7002809  -0.69596666]\\n  [-0.61803526 -0.6082668  -0.60642767]\\n  [-0.5558948  -0.57046324 -0.59524053]]\\n\\n [[-0.5584087  -0.5619373  -0.5744659 ]\\n  [-0.60510385 -0.5802763  -0.5907305 ]\\n  [-0.61694497 -0.55589324 -0.59315443]\\n  ...\\n  [-0.71316266 -0.7144597  -0.65562713]\\n  [-0.62904453 -0.59384894 -0.5559391 ]\\n  [-0.6673803  -0.667725   -0.6671463 ]]\\n\\n [[-0.55703044 -0.5463458  -0.5191123 ]\\n  [-0.53970224 -0.49998084 -0.5225193 ]\\n  [-0.55531585 -0.5167261  -0.5316111 ]\\n  ...\\n  [-0.6966244  -0.7041687  -0.6425341 ]\\n  [-0.53042525 -0.5079934  -0.46229053]\\n  [-0.46439797 -0.5104388  -0.50135607]]\\n\\n ...\\n\\n [[ 0.7684314   0.8806956   0.9020777 ]\\n  [ 0.55004394  0.8354144   0.92739576]\\n  [ 0.2053559   0.6938815   0.89285916]\\n  ...\\n  [ 0.5146159   0.45076168  0.38074565]\\n  [ 0.5077751   0.48318878  0.38308337]\\n  [ 0.38103613  0.35716513  0.2612215 ]]\\n\\n [[ 0.5970726   0.77560246  0.886816  ]\\n  [ 0.3078161   0.78520185  0.9002715 ]\\n  [ 0.19283424  0.7226255   0.8503383 ]\\n  ...\\n  [ 0.49694324  0.4725132   0.36233312]\\n  [ 0.4913761   0.4234206   0.36018938]\\n  [ 0.35868862  0.35483062  0.3554817 ]]\\n\\n [[ 0.22378577  0.5230688   0.71325547]\\n  [ 0.12510037  0.58206564  0.86857504]\\n  [ 0.00471767  0.5722435   0.8313632 ]\\n  ...\\n  [ 0.41076395  0.35539225  0.24901837]\\n  [ 0.4907982   0.42025086  0.33980078]\\n  [ 0.40406707  0.36447364  0.41718984]]]'"
     ]
    }
   ],
   "source": [
    "#Loading and preprocessing images\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = preprocess(image)\n",
    "    return image\n",
    "\n",
    "#Preprocessing images\n",
    "images = [load_and_preprocess_image(image_path) for image_path in image_paths]\n",
    "images = torch.stack(images)  \n",
    "#Stacking images into a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd80d5b3-e738-4ac4-a780-a32530c055d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a pre-trained CNN (ResNet) for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f3ab08a-ffe9-413e-b364-19d95e4930c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua.Turnbull\\AppData\\Local\\miniconda3\\envs\\pydata-book\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Joshua.Turnbull\\AppData\\Local\\miniconda3\\envs\\pydata-book\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\Joshua.Turnbull/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 97.8M/97.8M [00:06<00:00, 16.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing and loading model\n",
    "from torchvision import models\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()  \n",
    "#Setting the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f463afd1-59aa-4b70-ae13-82ffeb1a1b97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#Extracting features from the preprocessed images\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m image_features \u001b[38;5;241m=\u001b[39m extract_features(\u001b[43mimage\u001b[49m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(image_features\u001b[38;5;241m.\u001b[39mshape)  \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#Checking the shape of the feature vectors\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "#Extracting features using ResNet\n",
    "# Remove the final layer to extract features\n",
    "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "def extract_features(images):\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(images)\n",
    "    return features.squeeze()\n",
    "\n",
    "#Extracting features from the preprocessed images\n",
    "image_features = extract_features(image)\n",
    "print(image_features.shape)  \n",
    "#Checking the shape of the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcf3a683-71fb-44eb-aaf1-4c0c346115c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a sentiment classification model for image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31da5b70-3484-44f0-90b7-a6bbafa0ef63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m encoded_labels \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(labels)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Split data into training and testing sets\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mimage_features\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy(), encoded_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_features' is not defined"
     ]
    }
   ],
   "source": [
    "#Preparing data for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Example of sentiment labels\n",
    "labels = np.array([0, 1])\n",
    "\n",
    "#Encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_features.numpy(), encoded_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00d0d01b-b56c-40a5-92ec-99679d9c0052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.9055944055944056\n"
     ]
    }
   ],
   "source": [
    "#Taining the model using logistic rgeression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Training a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predicting and evaluating the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99f54871-2f2e-45d8-9675-78acf9b96cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fusion and Final Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cf95b87-94fa-4560-911a-cea1d36d9a82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Converting text and image features to numpy arrays\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m text_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mtext_features\u001b[49m\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m      6\u001b[0m image_features \u001b[38;5;241m=\u001b[39m image_features\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#Concatenating text and image features\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_features' is not defined"
     ]
    }
   ],
   "source": [
    "#Concatenating feature vectors\n",
    "import numpy as np\n",
    "\n",
    "#Converting text and image features to numpy arrays\n",
    "text_features = np.array(text_features.tolist())\n",
    "image_features = image_features.numpy()\n",
    "\n",
    "#Concatenating text and image features\n",
    "combined_features = np.concatenate((text_features, image_features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "327b618b-d17e-4056-920b-95729731a739",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Splitting combined features into training and testing sets\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mcombined_features\u001b[49m, encoded_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combined_features' is not defined"
     ]
    }
   ],
   "source": [
    "#Preparing data for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Splitting combined features into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, encoded_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "042802fb-a07a-4dab-b393-b7381f638b60",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#Initializing the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m SentimentClassifier(input_dim)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#Defining loss function and optimizer\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#Defining and training the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#Defining a simple fully connected neural network\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "#Initializing the model\n",
    "input_dim = X_train.shape[1]\n",
    "model = SentimentClassifier(input_dim)\n",
    "\n",
    "#Defining loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#Converting data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "#Training the model\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "160e8221-dce7-4f13-894c-206850933a51",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Evaluating the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      7\u001b[0m     y_pred_tensor \u001b[38;5;241m=\u001b[39m model(X_test_tensor)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "#Evaluating the final model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#Evaluating the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_test_tensor)\n",
    "    y_pred = torch.argmax(y_pred_tensor, dim=1).numpy()\n",
    "\n",
    "#Calculating performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='binary')\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299d7ee-47da-48c3-928d-fb57c32882d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
